<!doctype html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>JOSH</title>

  <script type="module" crossorigin src="/JOSH/assets/index-CejOEv1e.js"></script>
  <link rel="stylesheet" crossorigin href="/JOSH/assets/index-CG5cBysU.css">
</head>
<!-- === Header Ends === -->


<body>

<!-- === Home Section Starts === -->
<div class="section">
  <!-- === Title Starts === -->
  <div class="header">
    <div class="logo">
      <a href="https://genforce.github.io/" target="_blank"><img src="/JOSH/assets/genforce-D3nu1qs5.png"></a>
    </div>
    <div class="title" style="padding-top: 25pt;">  <!-- Set padding as 10 if title is with two lines. -->
      Joint Optimization for 4D Human-Scene Reconstruction in the Wild
    </div>
  </div>
  <!-- === Title Ends === -->
  <div class="author">
    <a href="https://scholar.google.com/citations?user=Asc7j9oAAAAJ&hl=en" target="_blank">Zhizheng Liu</a>&nbsp;, 
    <a href="https://github.com/joe-lin-tech" target="_blank">Joe Lin</a>&nbsp;,
    <a href="https://wywu.github.io/" target="_blank">Wayne Wu</a>&nbsp;,
    <a href="https://boleizhou.github.io/" target="_blank">Bolei Zhou</a>
  </div>
  <div class="institution">
    University of California, Los Angeles
  </div>
  <div class="link">
    <a href="#" target="_blank">[Paper]</a>&nbsp;
    <a href="https://github.com/genforce/JOSH" target="_blank">[Code]</a>
  </div>
 
    <b>TL;DR</b>: We propose a novel method <b>JOSH</b> for <b>4D Human-Scene Reconstruction in the wild</b>, which  jointly
    optimizes the <b>global human motion</b>, the <b>surrounding environment</b>, and the <b>camera poses</b> with coherent human-scene interaction given a web video captured from a single camera.
  
  <div class="teaser">
    <img src="/JOSH/assets/teaser-DH_ZweB3.jpg">
  </div>
  <div class="teaser">
    <img src="/JOSH/assets/demo-D96_gCs5.png">
  </div>
</div>
<!-- === Home Section Ends === -->
<!-- <div class="section">
  <div class="title">Interactive Demos on Web Videos</div>
<div id="demo1"> 
<script type="module" src="./src/demo1.js"></script>
</div>
<div id="demo2"> 
  <script type="module" src="./src/demo2.js"></script>
  </div>
  <div id="demo3"> 
    <script type="module" src="./src/demo3.js"></script>
    </div>
</div> -->
</div>

<!-- === Overview Section Starts === -->
<div class="section">
  <div class="title">Overview</div>
  <div class="body">
  We aim to capture human-scene interactions in the wild by reconstructing both the 4D global human motion and the 3D scene from monocular videos. We propose a novel method
  <b>JOSH</b> (<u>J</u>oint <u>O</u>ptimization of <u>S</u>cene  Geometry and <u>H</u>uman Motion)  that uses local scene reconstruction and human mesh recovery as initialization and then jointly optimizes motion and scene 
  with the <b>human-scene contact</b> constraints. We further propose an efficient model variant <b>JOSH3R</b>, which is trained only with <b>pseudo-labels of web videos annotated by JOSH</b>, to estimate human-scene 
  reconstruction in real-time. JOSH achieves state-of-the-art performance for both global human motion estimation and dense scene reconstruction with joint optimization, while  JOSH3R outperforms other optimization-free methods.
  </div>

  <div class="teaser">
    <img src="/JOSH/assets/method-D3CcHeIK.jpg">
  </div>


</div>

<!-- === Overview Section Ends === -->


<!-- === Result Section Starts === -->
<div class="section">
  <div class="title">Results on Datasets</div>
  JOSH surpasses existing methods on both global human motion estimation and metric-scale scene reconstruction by a large margin. It is also the only method that directly supports the task of 4D human-scene reconstruction.
  <br>
  <br>
  <div style="text-align: center;">
  Evaluation on Global Human Motion Estimation with the EMDB Dataset
  </div>
  <div class="body">
    <!-- Adjust the frame size based on the demo (EVERY project differs). -->
    <div style="position: relative; padding-top: 50.25%; margin: 0pt 0; text-align: center;">
      <video autoplay muted playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
          <source src="/JOSH/assets/dataset_1-BPl-oppn.mov" type="video/mp4">
          Your browser does not support the video tag.
      </video>
  </div>
  </div>
  <div style="text-align: center;">
    Evaluation on Global Camera Trajectory Estimation with the SLOPER4D Dataset
    </div>
    <div class="body">
      <!-- Adjust the frame size based on the demo (EVERY project differs). -->
      <div style="position: relative; padding-top: 40.25%; margin: 0pt 0; text-align: center;">
        <video autoplay muted playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
            <source src="/JOSH/assets/dataset_2-Vh3iZzzx.mov" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>
    </div>
    <div style="text-align: center;">
      Evaluation on 4D Human-Scene Reconstruction with the RICH Dataset
      </div>
      <div class="body">
        <!-- Adjust the frame size based on the demo (EVERY project differs). -->
        <div style="position: relative; padding-top: 48.25%; margin: 0pt 0; text-align: center;">
          <video autoplay muted playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
              <source src="/JOSH/assets/dataset_3-DhHm1EVt.mov" type="video/mp4">
              Your browser does not support the video tag.
          </video>
      </div>
      </div>
</div>

<div class="section">
  <div class="title">Results on Web Videos</div>
  JOSH can work with web videos to capture the diverse human motion and its scene background from the internet.
 
  <div class="body">
    <!-- Adjust the frame size based on the demo (EVERY project differs). -->
    <div style="position: relative; padding-top: 55.25%; margin: 0pt 0; text-align: center;">
      <video muted autoplay playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
          <source src="/JOSH/assets/demo_1-n-qPnaxm.mov" type="video/mp4">
          Your browser does not support the video tag.
      </video>
  </div>
  </div>
 
    <div class="body">
      <!-- Adjust the frame size based on the demo (EVERY project differs). -->
      <div style="position: relative; padding-top: 50.25%; margin: 0pt 0; text-align: center;">
        <video muted autoplay playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
            <source src="/JOSH/assets/demo_2-CgvWcERy.mov" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    </div>
    </div>
      <div class="body">
        <!-- Adjust the frame size based on the demo (EVERY project differs). -->
        <div style="position: relative; padding-top: 65.25%; margin: 0pt 0; text-align: center;">
          <video  autoplay muted playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
              <source src="/JOSH/assets/demo_3-COj8IJ0j.mov" type="video/mp4">
              Your browser does not support the video tag.
          </video>
      </div>
      </div>
</div>

<!-- === Result Section Ends === -->
<div class="section">
  <div class="title">Interactive Demos on Web Videos</div>
  Please feel free to drag the reconstruction results on the left to change the viewing angles and click on the scene components for interactive visualizations.
<div id="demo1"> 
</div>
</div> 

<!-- === Reference Section Starts === -->
<div class="section">
  <div class="bibtex">BibTeX</div>
<pre>
@article{alias,
  title   = {},
  author  = {},
  journal = {},
  year    = {}
}
</pre>

  <!-- BZ: we should give other related work enough credits, -->
  <!--     so please include some most relevant work and leave some comment to summarize work and the difference. -->
  <div class="ref">Related Work</div>
  <div class="citation">
    <div class="image"><img src="/JOSH/assets/pedgen-wcEJXiGT.gif"></div>
    <div class="comment">
      <a href="https://genforce.github.io/PedGen/" target="_blank">
        Zhizheng Liu, Joe Lin, Wayne Wu, Bolei Zhou.
        Learning to Generate Diverse Pedestrian Movements from Web Videos with Noisy Labels.
        Preprint (arXiv) , 2024.</a><br>
      <b>Comment:</b>
       This work proposes a dataset and a model for context-aware pedestrian movement generation from pseudo-labels of web videos. We can use JOSH to 
       extract human and scene labels with better quality for pedestrian movement generation.
    </div>
  </div>
  <div class="citation">
    <div class="image"><img src="/JOSH/assets/mast3r-CA05dMCk.jpg"></div>
    <div class="comment">
      <a href="https://europe.naverlabs.com/research/publications/mast3r-sfm-a-fully-integrated-solution-for-unconstrained-structure-from-motion/" target="_blank">
        Bardienus Duisterhof, Lojze Zust, Philippe Weinzaepfel, Vincent Leroy, Yohann Cabon, JÃ©rome Revaud.
        MASt3R-SfM: a fully-Integrated solution for unconstrained Structure-from-Motion.
        Preprint (arXiv) , 2024.</a><br>
      <b>Comment:</b>
      This work proposes an efficient and robust pipeline for dense scene reconstruction from an unconstrained collection of images. In our implementation of JOSH, we use its results as the initialization of the local scene reconstruction.
    </div>
  </div>
</div>
<!-- === Reference Section Ends === -->




</body>
</html>
